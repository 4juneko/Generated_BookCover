{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c98786c34d004028a13c8c06c4c0efee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7aea453302324ae68697f636a48b1b33",
              "IPY_MODEL_e173ab8c0d5c43f0bc545677b0e7faee",
              "IPY_MODEL_758201684fd4430796d63033103ee71b"
            ],
            "layout": "IPY_MODEL_81de710ebd56477ca93f0ad3cd0102f2"
          }
        },
        "7aea453302324ae68697f636a48b1b33": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f418e99a5aa7459bac282aae8e1cfd28",
            "placeholder": "​",
            "style": "IPY_MODEL_5bb4a1e686794f40931244e8c67b7c54",
            "value": "100%"
          }
        },
        "e173ab8c0d5c43f0bc545677b0e7faee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d3511d890d7146598bc4592e6ad36f78",
            "max": 30,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cee54dac7f4e4a2b8953ea19ed9f585f",
            "value": 30
          }
        },
        "758201684fd4430796d63033103ee71b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_074b64f21bdf4169aa47ca2b75c4ae19",
            "placeholder": "​",
            "style": "IPY_MODEL_067f3019a47248d38e55616b8d9e3f45",
            "value": " 30/30 [00:01&lt;00:00, 17.56it/s]"
          }
        },
        "81de710ebd56477ca93f0ad3cd0102f2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f418e99a5aa7459bac282aae8e1cfd28": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5bb4a1e686794f40931244e8c67b7c54": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d3511d890d7146598bc4592e6ad36f78": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cee54dac7f4e4a2b8953ea19ed9f585f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "074b64f21bdf4169aa47ca2b75c4ae19": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "067f3019a47248d38e55616b8d9e3f45": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LxQ4apB1iDrD",
        "outputId": "665154b1-8354-465a-f7e7-2ed3352f2741"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'diffusers'...\n",
            "remote: Enumerating objects: 29150, done.\u001b[K\n",
            "remote: Counting objects: 100% (1102/1102), done.\u001b[K\n",
            "remote: Compressing objects: 100% (539/539), done.\u001b[K\n",
            "remote: Total 29150 (delta 728), reused 768 (delta 491), pack-reused 28048\u001b[K\n",
            "Receiving objects: 100% (29150/29150), 19.51 MiB | 17.37 MiB/s, done.\n",
            "Resolving deltas: 100% (21279/21279), done.\n",
            "Processing /content/diffusers\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting importlib-metadata (from diffusers==0.18.0.dev0)\n",
            "  Downloading importlib_metadata-6.8.0-py3-none-any.whl (22 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from diffusers==0.18.0.dev0) (3.12.2)\n",
            "Collecting huggingface-hub>=0.13.2 (from diffusers==0.18.0.dev0)\n",
            "  Downloading huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from diffusers==0.18.0.dev0) (1.22.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from diffusers==0.18.0.dev0) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from diffusers==0.18.0.dev0) (2.27.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from diffusers==0.18.0.dev0) (8.4.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.13.2->diffusers==0.18.0.dev0) (2023.6.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.13.2->diffusers==0.18.0.dev0) (4.65.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.13.2->diffusers==0.18.0.dev0) (6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.13.2->diffusers==0.18.0.dev0) (4.6.3)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.13.2->diffusers==0.18.0.dev0) (23.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata->diffusers==0.18.0.dev0) (3.15.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers==0.18.0.dev0) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers==0.18.0.dev0) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers==0.18.0.dev0) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers==0.18.0.dev0) (3.4)\n",
            "Building wheels for collected packages: diffusers\n",
            "  Building wheel for diffusers (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for diffusers: filename=diffusers-0.18.0.dev0-py3-none-any.whl size=1247849 sha256=1d5d75c6cd76405cd8fa5b9f4781d2e55775a5bfe25ccc5765b31233e1da6995\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-_hb_wgas/wheels/95/c5/3b/e1b4269f8a2584de57e75f949a185b48fc4144e9a91fc9965a\n",
            "Successfully built diffusers\n",
            "Installing collected packages: importlib-metadata, huggingface-hub, diffusers\n",
            "Successfully installed diffusers-0.18.0.dev0 huggingface-hub-0.16.4 importlib-metadata-6.8.0\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# GitHub 저장소 복제\n",
        "!git clone https://github.com/huggingface/diffusers\n",
        "\n",
        "# 디렉토리 변경\n",
        "os.chdir('diffusers')\n",
        "\n",
        "# 필요한 패키지 설치\n",
        "!pip install ."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.chdir('/content/diffusers/examples/text_to_image')"
      ],
      "metadata": {
        "id": "oJ7MrjqAioYi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DTi_wXKRiocC",
        "outputId": "4a5b4f9b-bb3a-4f57-edd5-a1dbd59c65d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting accelerate>=0.16.0 (from -r requirements.txt (line 1))\n",
            "  Downloading accelerate-0.20.3-py3-none-any.whl (227 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/227.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.6/227.6 kB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 2)) (0.15.2+cu118)\n",
            "Collecting transformers>=4.25.1 (from -r requirements.txt (line 3))\n",
            "  Downloading transformers-4.30.2-py3-none-any.whl (7.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m116.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting datasets (from -r requirements.txt (line 4))\n",
            "  Downloading datasets-2.13.1-py3-none-any.whl (486 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m486.2/486.2 kB\u001b[0m \u001b[31m50.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ftfy (from -r requirements.txt (line 5))\n",
            "  Downloading ftfy-6.1.1-py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.1/53.1 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tensorboard in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 6)) (2.12.3)\n",
            "Requirement already satisfied: Jinja2 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 7)) (3.1.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.16.0->-r requirements.txt (line 1)) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.16.0->-r requirements.txt (line 1)) (23.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.16.0->-r requirements.txt (line 1)) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.16.0->-r requirements.txt (line 1)) (6.0)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.16.0->-r requirements.txt (line 1)) (2.0.1+cu118)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision->-r requirements.txt (line 2)) (2.27.1)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->-r requirements.txt (line 2)) (8.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate>=0.16.0->-r requirements.txt (line 1)) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate>=0.16.0->-r requirements.txt (line 1)) (4.6.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate>=0.16.0->-r requirements.txt (line 1)) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate>=0.16.0->-r requirements.txt (line 1)) (3.1)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate>=0.16.0->-r requirements.txt (line 1)) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->accelerate>=0.16.0->-r requirements.txt (line 1)) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->accelerate>=0.16.0->-r requirements.txt (line 1)) (16.0.6)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.25.1->-r requirements.txt (line 3)) (0.16.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.25.1->-r requirements.txt (line 3)) (2022.10.31)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers>=4.25.1->-r requirements.txt (line 3))\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m114.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors>=0.3.1 (from transformers>=4.25.1->-r requirements.txt (line 3))\n",
            "  Downloading safetensors-0.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m78.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.25.1->-r requirements.txt (line 3)) (4.65.0)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets->-r requirements.txt (line 4)) (9.0.0)\n",
            "Collecting dill<0.3.7,>=0.3.0 (from datasets->-r requirements.txt (line 4))\n",
            "  Downloading dill-0.3.6-py3-none-any.whl (110 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 kB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets->-r requirements.txt (line 4)) (1.5.3)\n",
            "Collecting xxhash (from datasets->-r requirements.txt (line 4))\n",
            "  Downloading xxhash-3.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.5/212.5 kB\u001b[0m \u001b[31m29.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess (from datasets->-r requirements.txt (line 4))\n",
            "  Downloading multiprocess-0.70.14-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.3/134.3 kB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.10/dist-packages (from datasets->-r requirements.txt (line 4)) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets->-r requirements.txt (line 4)) (3.8.4)\n",
            "Requirement already satisfied: wcwidth>=0.2.5 in /usr/local/lib/python3.10/dist-packages (from ftfy->-r requirements.txt (line 5)) (0.2.6)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 6)) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 6)) (1.56.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 6)) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 6)) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 6)) (3.4.3)\n",
            "Requirement already satisfied: protobuf>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 6)) (3.20.3)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 6)) (67.7.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 6)) (0.7.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 6)) (2.3.6)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 6)) (0.40.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2->-r requirements.txt (line 7)) (2.1.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r requirements.txt (line 4)) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r requirements.txt (line 4)) (2.0.12)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r requirements.txt (line 4)) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r requirements.txt (line 4)) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r requirements.txt (line 4)) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r requirements.txt (line 4)) (1.3.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r requirements.txt (line 4)) (1.3.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->-r requirements.txt (line 6)) (5.3.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->-r requirements.txt (line 6)) (0.3.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->-r requirements.txt (line 6)) (1.16.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->-r requirements.txt (line 6)) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard->-r requirements.txt (line 6)) (1.3.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->-r requirements.txt (line 2)) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->-r requirements.txt (line 2)) (2023.5.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->-r requirements.txt (line 2)) (3.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->-r requirements.txt (line 4)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->-r requirements.txt (line 4)) (2022.7.1)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->-r requirements.txt (line 6)) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard->-r requirements.txt (line 6)) (3.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6.0->accelerate>=0.16.0->-r requirements.txt (line 1)) (1.3.0)\n",
            "Installing collected packages: tokenizers, safetensors, xxhash, ftfy, dill, multiprocess, transformers, datasets, accelerate\n",
            "Successfully installed accelerate-0.20.3 datasets-2.13.1 dill-0.3.6 ftfy-6.1.1 multiprocess-0.70.14 safetensors-0.3.1 tokenizers-0.13.3 transformers-4.30.2 xxhash-3.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!accelerate config default"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FY_ZhyZw0J4F",
        "outputId": "79872e6c-4495-4e37-ecff-792407720077"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-07-08 16:23:02.772268: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "accelerate configuration saved at /root/.cache/huggingface/accelerate/default_config.yaml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!huggingface-cli login"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lYlC2gKAR0T_",
        "outputId": "ffefcce5-af0c-4beb-c538-65f9b48796c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n",
            "    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n",
            "    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n",
            "    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n",
            "    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n",
            "    \n",
            "    To login, `huggingface_hub` requires a token generated from https://huggingface.co/settings/tokens .\n",
            "Token: \n",
            "Add token as git credential? (Y/n) n\n",
            "Token is valid (permission: read).\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!export MODEL_NAME=\"CompVis/stable-diffusion-v1-4\"\n",
        "!export DATASET_NAME=\"lambdalabs/pokemon-blip-captions\""
      ],
      "metadata": {
        "id": "gkPjbpyOR0Wk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install --upgrade tensorrt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ycjrKCtCJ0VM",
        "outputId": "3deed28f-efcd-4272-f848-503af7e816fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorrt\n",
            "  Downloading tensorrt-8.6.1.tar.gz (16 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: tensorrt\n",
            "  Building wheel for tensorrt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tensorrt: filename=tensorrt-8.6.1-py2.py3-none-any.whl size=16973 sha256=3c2fa8079744aa18d888819cae189ec52417e460868eed85deff6ea6e647ff7d\n",
            "  Stored in directory: /root/.cache/pip/wheels/6d/29/56/abdffd4c604f255b5254bef3f1c598ab7811ea020540599438\n",
            "Successfully built tensorrt\n",
            "Installing collected packages: tensorrt\n",
            "Successfully installed tensorrt-8.6.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "tensorrt, wandb를 깔았다가 wandb는 왠지 안해도 될 것 같아서(ㅋㅋ..) 지웠다."
      ],
      "metadata": {
        "id": "S_C-_qB9bQjX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!accelerate launch --mixed_precision=\"fp16\" train_text_to_image_lora.py \\\n",
        "  --pretrained_model_name_or_path='CompVis/stable-diffusion-v1-4' \\\n",
        "  --dataset_name='lambdalabs/pokemon-blip-captions' --caption_column=\"text\" \\\n",
        "  --resolution=512 --random_flip \\\n",
        "  --train_batch_size=1 \\\n",
        "  --num_train_epochs=100 --checkpointing_steps=5000 \\\n",
        "  --learning_rate=1e-04 --lr_scheduler=\"constant\" --lr_warmup_steps=0 \\\n",
        "  --seed=42 \\\n",
        "  --output_dir=\"sd-pokemon-model-lora\" \\\n",
        "  --validation_prompt=\"cute dragon creature\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zcMm38svR0Yz",
        "outputId": "1ee20bd2-1970-4edc-8ddd-66908774d8f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-07-08 16:25:03.517881: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-07-08 16:25:08.741496: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "07/08/2023 16:25:10 - INFO - __main__ - Distributed environment: NO\n",
            "Num processes: 1\n",
            "Process index: 0\n",
            "Local process index: 0\n",
            "Device: cuda\n",
            "\n",
            "Mixed precision type: fp16\n",
            "\n",
            "Downloading (…)cheduler_config.json: 100% 313/313 [00:00<00:00, 2.07MB/s]\n",
            "{'timestep_spacing', 'dynamic_thresholding_ratio', 'clip_sample_range', 'prediction_type', 'thresholding', 'sample_max_value', 'variance_type'} was not found in config. Values will be initialized to default values.\n",
            "Downloading (…)tokenizer/vocab.json: 100% 1.06M/1.06M [00:00<00:00, 1.67MB/s]\n",
            "Downloading (…)tokenizer/merges.txt: 100% 525k/525k [00:00<00:00, 824kB/s]\n",
            "Downloading (…)cial_tokens_map.json: 100% 472/472 [00:00<00:00, 3.27MB/s]\n",
            "Downloading (…)okenizer_config.json: 100% 806/806 [00:00<00:00, 5.16MB/s]\n",
            "Downloading (…)_encoder/config.json: 100% 592/592 [00:00<00:00, 4.07MB/s]\n",
            "Downloading model.safetensors: 100% 492M/492M [00:01<00:00, 492MB/s]\n",
            "Downloading (…)main/vae/config.json: 100% 551/551 [00:00<00:00, 2.15MB/s]\n",
            "Downloading (…)ch_model.safetensors: 100% 335M/335M [00:00<00:00, 364MB/s]\n",
            "{'norm_num_groups'} was not found in config. Values will be initialized to default values.\n",
            "Downloading (…)ain/unet/config.json: 100% 743/743 [00:00<00:00, 3.44MB/s]\n",
            "Downloading (…)ch_model.safetensors: 100% 3.44G/3.44G [00:11<00:00, 300MB/s]\n",
            "{'dual_cross_attention', 'use_linear_projection', 'time_embedding_act_fn', 'transformer_layers_per_block', 'upcast_attention', 'cross_attention_norm', 'mid_block_type', 'addition_embed_type', 'class_embeddings_concat', 'encoder_hid_dim_type', 'time_embedding_type', 'resnet_time_scale_shift', 'class_embed_type', 'resnet_skip_time_act', 'addition_embed_type_num_heads', 'addition_time_embed_dim', 'time_embedding_dim', 'timestep_post_act', 'time_cond_proj_dim', 'only_cross_attention', 'encoder_hid_dim', 'projection_class_embeddings_input_dim', 'num_class_embeds', 'conv_in_kernel', 'resnet_out_scale_factor', 'mid_block_only_cross_attention', 'num_attention_heads', 'conv_out_kernel'} was not found in config. Values will be initialized to default values.\n",
            "Downloading metadata: 100% 731/731 [00:00<00:00, 5.72MB/s]\n",
            "Downloading readme: 100% 1.80k/1.80k [00:00<00:00, 14.0MB/s]\n",
            "Downloading and preparing dataset imagefolder/pokemon (download: 95.05 MiB, generated: 113.89 MiB, post-processed: Unknown size, total: 208.94 MiB) to /root/.cache/huggingface/datasets/lambdalabs___parquet/lambdalabs--pokemon-blip-captions-10e3527a764857bd/0.0.0/14a00e99c0d15a23649d0db8944380ac81082d4b021f398733dd84f3a6c569a7...\n",
            "Downloading data files:   0% 0/1 [00:00<?, ?it/s]\n",
            "Downloading data:   0% 0.00/99.7M [00:00<?, ?B/s]\u001b[A\n",
            "Downloading data:  10% 10.1M/99.7M [00:00<00:00, 101MB/s]\u001b[A\n",
            "Downloading data:  23% 23.1M/99.7M [00:00<00:00, 118MB/s]\u001b[A\n",
            "Downloading data:  36% 36.3M/99.7M [00:00<00:00, 125MB/s]\u001b[A\n",
            "Downloading data:  49% 49.3M/99.7M [00:00<00:00, 127MB/s]\u001b[A\n",
            "Downloading data:  63% 62.3M/99.7M [00:00<00:00, 128MB/s]\u001b[A\n",
            "Downloading data:  76% 75.3M/99.7M [00:00<00:00, 129MB/s]\u001b[A\n",
            "Downloading data: 100% 99.7M/99.7M [00:00<00:00, 126MB/s]\n",
            "Downloading data files: 100% 1/1 [00:01<00:00,  1.83s/it]\n",
            "Extracting data files: 100% 1/1 [00:00<00:00, 1457.37it/s]\n",
            "Dataset parquet downloaded and prepared to /root/.cache/huggingface/datasets/lambdalabs___parquet/lambdalabs--pokemon-blip-captions-10e3527a764857bd/0.0.0/14a00e99c0d15a23649d0db8944380ac81082d4b021f398733dd84f3a6c569a7. Subsequent calls will reuse this data.\n",
            "100% 1/1 [00:00<00:00, 230.39it/s]\n",
            "07/08/2023 16:25:48 - INFO - __main__ - ***** Running training *****\n",
            "07/08/2023 16:25:48 - INFO - __main__ -   Num examples = 833\n",
            "07/08/2023 16:25:48 - INFO - __main__ -   Num Epochs = 100\n",
            "07/08/2023 16:25:48 - INFO - __main__ -   Instantaneous batch size per device = 1\n",
            "07/08/2023 16:25:48 - INFO - __main__ -   Total train batch size (w. parallel, distributed & accumulation) = 1\n",
            "07/08/2023 16:25:48 - INFO - __main__ -   Gradient Accumulation steps = 1\n",
            "07/08/2023 16:25:48 - INFO - __main__ -   Total optimization steps = 83300\n",
            "Steps:   1% 833/83300 [02:58<4:34:53,  5.00it/s, lr=0.0001, step_loss=0.00978]07/08/2023 16:28:47 - INFO - __main__ - Running validation... \n",
            " Generating 4 images with prompt: cute dragon creature.\n",
            "\n",
            "Downloading (…)ain/model_index.json: 100% 541/541 [00:00<00:00, 3.43MB/s]\n",
            "\n",
            "Fetching 14 files:   0% 0/14 [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "Downloading model.safetensors:   0% 0.00/1.22G [00:00<?, ?B/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.safetensors:   4% 52.4M/1.22G [00:00<00:02, 499MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)rocessor_config.json: 100% 342/342 [00:00<00:00, 2.00MB/s]\n",
            "\n",
            "Fetching 14 files:   7% 1/14 [00:00<00:06,  2.09it/s]\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)nfig-checkpoint.json: 100% 209/209 [00:00<00:00, 1.71MB/s]\n",
            "\n",
            "\n",
            "Downloading model.safetensors:   9% 105M/1.22G [00:00<00:02, 496MB/s] \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)_checker/config.json: 100% 4.56k/4.56k [00:00<00:00, 22.6MB/s]\n",
            "\n",
            "\n",
            "Downloading model.safetensors:  14% 168M/1.22G [00:00<00:01, 539MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.safetensors:  19% 231M/1.22G [00:00<00:01, 550MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.safetensors:  24% 294M/1.22G [00:00<00:01, 516MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.safetensors:  28% 346M/1.22G [00:00<00:01, 488MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.safetensors:  33% 398M/1.22G [00:00<00:01, 452MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.safetensors:  37% 451M/1.22G [00:00<00:01, 449MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.safetensors:  42% 514M/1.22G [00:01<00:01, 466MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.safetensors:  47% 566M/1.22G [00:01<00:01, 451MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.safetensors:  51% 619M/1.22G [00:01<00:01, 423MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.safetensors:  55% 671M/1.22G [00:01<00:01, 445MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.safetensors:  60% 734M/1.22G [00:01<00:01, 478MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.safetensors:  66% 797M/1.22G [00:01<00:00, 499MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.safetensors:  71% 860M/1.22G [00:01<00:00, 523MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.safetensors:  76% 923M/1.22G [00:01<00:00, 502MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.safetensors:  80% 975M/1.22G [00:02<00:00, 498MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.safetensors:  85% 1.03G/1.22G [00:02<00:00, 486MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.safetensors:  89% 1.08G/1.22G [00:02<00:00, 452MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.safetensors:  93% 1.13G/1.22G [00:02<00:00, 440MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.safetensors: 100% 1.22G/1.22G [00:02<00:00, 471MB/s]\n",
            "\n",
            "Fetching 14 files: 100% 14/14 [00:02<00:00,  4.89it/s]\n",
            "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
            "{'norm_num_groups'} was not found in config. Values will be initialized to default values.\n",
            "{'prediction_type', 'timestep_spacing'} was not found in config. Values will be initialized to default values.\n",
            "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
            "Steps:   2% 1666/83300 [06:08<4:18:35,  5.26it/s, lr=0.0001, step_loss=0.101] 07/08/2023 16:31:57 - INFO - __main__ - Running validation... \n",
            " Generating 4 images with prompt: cute dragon creature.\n",
            "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
            "{'norm_num_groups'} was not found in config. Values will be initialized to default values.\n",
            "{'prediction_type', 'timestep_spacing'} was not found in config. Values will be initialized to default values.\n",
            "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
            "Steps:   3% 2499/83300 [09:14<4:25:11,  5.08it/s, lr=0.0001, step_loss=0.0541]07/08/2023 16:35:02 - INFO - __main__ - Running validation... \n",
            " Generating 4 images with prompt: cute dragon creature.\n",
            "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
            "{'norm_num_groups'} was not found in config. Values will be initialized to default values.\n",
            "{'prediction_type', 'timestep_spacing'} was not found in config. Values will be initialized to default values.\n",
            "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
            "Steps:   4% 3332/83300 [12:20<4:37:14,  4.81it/s, lr=0.0001, step_loss=0.0274] 07/08/2023 16:38:08 - INFO - __main__ - Running validation... \n",
            " Generating 4 images with prompt: cute dragon creature.\n",
            "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
            "{'norm_num_groups'} was not found in config. Values will be initialized to default values.\n",
            "{'prediction_type', 'timestep_spacing'} was not found in config. Values will be initialized to default values.\n",
            "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
            "Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.\n",
            "Steps:   5% 4165/83300 [15:25<4:28:01,  4.92it/s, lr=0.0001, step_loss=0.0164]07/08/2023 16:41:14 - INFO - __main__ - Running validation... \n",
            " Generating 4 images with prompt: cute dragon creature.\n",
            "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
            "{'norm_num_groups'} was not found in config. Values will be initialized to default values.\n",
            "{'prediction_type', 'timestep_spacing'} was not found in config. Values will be initialized to default values.\n",
            "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
            "Steps:   6% 4998/83300 [18:32<4:19:08,  5.04it/s, lr=0.0001, step_loss=0.00229]07/08/2023 16:44:21 - INFO - __main__ - Running validation... \n",
            " Generating 4 images with prompt: cute dragon creature.\n",
            "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
            "{'norm_num_groups'} was not found in config. Values will be initialized to default values.\n",
            "{'prediction_type', 'timestep_spacing'} was not found in config. Values will be initialized to default values.\n",
            "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
            "Steps:   6% 5000/83300 [18:45<60:47:22,  2.79s/it, lr=0.0001, step_loss=0.0138]07/08/2023 16:44:33 - INFO - accelerate.accelerator - Saving current state to sd-pokemon-model-lora/checkpoint-5000\n",
            "07/08/2023 16:44:33 - INFO - accelerate.checkpointing - Model weights saved in sd-pokemon-model-lora/checkpoint-5000/pytorch_model.bin\n",
            "07/08/2023 16:44:33 - INFO - accelerate.checkpointing - Optimizer state saved in sd-pokemon-model-lora/checkpoint-5000/optimizer.bin\n",
            "07/08/2023 16:44:33 - INFO - accelerate.checkpointing - Scheduler state saved in sd-pokemon-model-lora/checkpoint-5000/scheduler.bin\n",
            "07/08/2023 16:44:33 - INFO - accelerate.checkpointing - Gradient scaler state saved in sd-pokemon-model-lora/checkpoint-5000/scaler.pt\n",
            "07/08/2023 16:44:33 - INFO - accelerate.checkpointing - Random states saved in sd-pokemon-model-lora/checkpoint-5000/random_states_0.pkl\n",
            "07/08/2023 16:44:33 - INFO - __main__ - Saved state to sd-pokemon-model-lora/checkpoint-5000\n",
            "Steps:   7% 5831/83300 [21:38<4:20:31,  4.96it/s, lr=0.0001, step_loss=0.0141] 07/08/2023 16:47:26 - INFO - __main__ - Running validation... \n",
            " Generating 4 images with prompt: cute dragon creature.\n",
            "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
            "{'norm_num_groups'} was not found in config. Values will be initialized to default values.\n",
            "{'prediction_type', 'timestep_spacing'} was not found in config. Values will be initialized to default values.\n",
            "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
            "Steps:   8% 6664/83300 [24:44<4:16:46,  4.97it/s, lr=0.0001, step_loss=0.00333]07/08/2023 16:50:32 - INFO - __main__ - Running validation... \n",
            " Generating 4 images with prompt: cute dragon creature.\n",
            "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
            "{'norm_num_groups'} was not found in config. Values will be initialized to default values.\n",
            "{'prediction_type', 'timestep_spacing'} was not found in config. Values will be initialized to default values.\n",
            "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
            "Steps:   9% 7370/83300 [27:24<4:15:20,  4.96it/s, lr=0.0001, step_loss=0.0427]\u001b[31m╭─\u001b[0m\u001b[31m────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m─────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[2;33m/usr/lib/python3.10/\u001b[0m\u001b[1;33msubprocess.py\u001b[0m:\u001b[94m1209\u001b[0m in \u001b[92mwait\u001b[0m                               \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1206 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m timeout \u001b[95mis\u001b[0m \u001b[95mnot\u001b[0m \u001b[94mNone\u001b[0m:                                       \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1207 \u001b[0m\u001b[2m│   │   │   \u001b[0mendtime = _time() + timeout                               \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1208 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mtry\u001b[0m:                                                          \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1209 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96mself\u001b[0m._wait(timeout=timeout)                        \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1210 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mexcept\u001b[0m \u001b[96mKeyboardInterrupt\u001b[0m:                                     \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1211 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[2m# https://bugs.python.org/issue25942\u001b[0m                      \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1212 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[2m# The first keyboard interrupt waits briefly for the chil\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[2;33m/usr/lib/python3.10/\u001b[0m\u001b[1;33msubprocess.py\u001b[0m:\u001b[94m1959\u001b[0m in \u001b[92m_wait\u001b[0m                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1956 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0m\u001b[94mwith\u001b[0m \u001b[96mself\u001b[0m._waitpid_lock:                          \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1957 \u001b[0m\u001b[2m│   │   │   │   │   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mself\u001b[0m.returncode \u001b[95mis\u001b[0m \u001b[95mnot\u001b[0m \u001b[94mNone\u001b[0m:               \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1958 \u001b[0m\u001b[2m│   │   │   │   │   │   │   \u001b[0m\u001b[94mbreak\u001b[0m  \u001b[2m# Another thread waited.\u001b[0m           \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1959 \u001b[2m│   │   │   │   │   │   \u001b[0m(pid, sts) = \u001b[96mself\u001b[0m._try_wait(\u001b[94m0\u001b[0m)                \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1960 \u001b[0m\u001b[2m│   │   │   │   │   │   \u001b[0m\u001b[2m# Check the pid and loop as waitpid has been \u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1961 \u001b[0m\u001b[2m│   │   │   │   │   │   \u001b[0m\u001b[2m# return 0 even without WNOHANG in odd situat\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1962 \u001b[0m\u001b[2m│   │   │   │   │   │   \u001b[0m\u001b[2m# http://bugs.python.org/issue14396.\u001b[0m          \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[2;33m/usr/lib/python3.10/\u001b[0m\u001b[1;33msubprocess.py\u001b[0m:\u001b[94m1917\u001b[0m in \u001b[92m_try_wait\u001b[0m                          \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1914 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92m_try_wait\u001b[0m(\u001b[96mself\u001b[0m, wait_flags):                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1915 \u001b[0m\u001b[2;90m│   │   │   \u001b[0m\u001b[33m\"\"\"All callers to this function MUST hold self._waitpid_l\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1916 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mtry\u001b[0m:                                                      \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1917 \u001b[2m│   │   │   │   \u001b[0m(pid, sts) = os.waitpid(\u001b[96mself\u001b[0m.pid, wait_flags)         \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1918 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mexcept\u001b[0m \u001b[96mChildProcessError\u001b[0m:                                 \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1919 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[2m# This happens if SIGCLD is set to be ignored or wait\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1920 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[2m# for child processes has otherwise been disabled for\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
            "\u001b[1;91mKeyboardInterrupt\u001b[0m\n",
            "\n",
            "\u001b[3mDuring handling of the above exception, another exception occurred:\u001b[0m\n",
            "\n",
            "\u001b[31m╭─\u001b[0m\u001b[31m────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m─────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/bin/\u001b[0m\u001b[1;33maccelerate\u001b[0m:\u001b[94m8\u001b[0m in \u001b[92m<module>\u001b[0m                                      \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m5 \u001b[0m\u001b[94mfrom\u001b[0m \u001b[4;96maccelerate\u001b[0m\u001b[4;96m.\u001b[0m\u001b[4;96mcommands\u001b[0m\u001b[4;96m.\u001b[0m\u001b[4;96maccelerate_cli\u001b[0m \u001b[94mimport\u001b[0m main                      \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m6 \u001b[0m\u001b[94mif\u001b[0m \u001b[91m__name__\u001b[0m == \u001b[33m'\u001b[0m\u001b[33m__main__\u001b[0m\u001b[33m'\u001b[0m:                                               \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m7 \u001b[0m\u001b[2m│   \u001b[0msys.argv[\u001b[94m0\u001b[0m] = re.sub(\u001b[33mr\u001b[0m\u001b[33m'\u001b[0m\u001b[33m(-script\u001b[0m\u001b[33m\\\u001b[0m\u001b[33m.pyw|\u001b[0m\u001b[33m\\\u001b[0m\u001b[33m.exe)?$\u001b[0m\u001b[33m'\u001b[0m, \u001b[33m'\u001b[0m\u001b[33m'\u001b[0m, sys.argv[\u001b[94m0\u001b[0m])     \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m8 \u001b[2m│   \u001b[0msys.exit(main())                                                     \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m9 \u001b[0m                                                                         \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/accelerate/commands/\u001b[0m\u001b[1;33maccelerate_cli.p\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[1;33my\u001b[0m:\u001b[94m45\u001b[0m in \u001b[92mmain\u001b[0m                                                                 \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m42 \u001b[0m\u001b[2m│   │   \u001b[0mexit(\u001b[94m1\u001b[0m)                                                         \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m43 \u001b[0m\u001b[2m│   \u001b[0m                                                                    \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m44 \u001b[0m\u001b[2m│   \u001b[0m\u001b[2m# Run\u001b[0m                                                               \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m45 \u001b[2m│   \u001b[0margs.func(args)                                                     \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m46 \u001b[0m                                                                        \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m47 \u001b[0m                                                                        \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m48 \u001b[0m\u001b[94mif\u001b[0m \u001b[91m__name__\u001b[0m == \u001b[33m\"\u001b[0m\u001b[33m__main__\u001b[0m\u001b[33m\"\u001b[0m:                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/accelerate/commands/\u001b[0m\u001b[1;33mlaunch.py\u001b[0m:\u001b[94m941\u001b[0m in \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[92mlaunch_command\u001b[0m                                                               \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m938 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94melif\u001b[0m defaults \u001b[95mis\u001b[0m \u001b[95mnot\u001b[0m \u001b[94mNone\u001b[0m \u001b[95mand\u001b[0m defaults.compute_environment == Comp \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m939 \u001b[0m\u001b[2m│   │   \u001b[0msagemaker_launcher(defaults, args)                             \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m940 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94melse\u001b[0m:                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m941 \u001b[2m│   │   \u001b[0msimple_launcher(args)                                          \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m942 \u001b[0m                                                                       \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m943 \u001b[0m                                                                       \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m944 \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mmain\u001b[0m():                                                            \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/accelerate/commands/\u001b[0m\u001b[1;33mlaunch.py\u001b[0m:\u001b[94m600\u001b[0m in \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[92msimple_launcher\u001b[0m                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m597 \u001b[0m\u001b[2m│   \u001b[0mcmd, current_env = prepare_simple_launcher_cmd_env(args)           \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m598 \u001b[0m\u001b[2m│   \u001b[0m                                                                   \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m599 \u001b[0m\u001b[2m│   \u001b[0mprocess = subprocess.Popen(cmd, env=current_env)                   \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m600 \u001b[2m│   \u001b[0mprocess.wait()                                                     \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m601 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mif\u001b[0m process.returncode != \u001b[94m0\u001b[0m:                                        \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m602 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m args.quiet:                                             \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m603 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mraise\u001b[0m subprocess.CalledProcessError(returncode=process.ret \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[2;33m/usr/lib/python3.10/\u001b[0m\u001b[1;33msubprocess.py\u001b[0m:\u001b[94m1222\u001b[0m in \u001b[92mwait\u001b[0m                               \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1219 \u001b[0m\u001b[2m│   │   │   │   \u001b[0msigint_timeout = \u001b[96mself\u001b[0m._sigint_wait_secs               \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1220 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[96mself\u001b[0m._sigint_wait_secs = \u001b[94m0\u001b[0m  \u001b[2m# nothing else should wait.\u001b[0m   \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1221 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mtry\u001b[0m:                                                      \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1222 \u001b[2m│   │   │   │   \u001b[0m\u001b[96mself\u001b[0m._wait(timeout=sigint_timeout)                    \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1223 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mexcept\u001b[0m TimeoutExpired:                                    \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1224 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[94mpass\u001b[0m                                                  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1225 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mraise\u001b[0m  \u001b[2m# resume the KeyboardInterrupt\u001b[0m                     \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[2;33m/usr/lib/python3.10/\u001b[0m\u001b[1;33msubprocess.py\u001b[0m:\u001b[94m1953\u001b[0m in \u001b[92m_wait\u001b[0m                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1950 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0m\u001b[94mif\u001b[0m remaining <= \u001b[94m0\u001b[0m:                                \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1951 \u001b[0m\u001b[2m│   │   │   │   │   │   \u001b[0m\u001b[94mraise\u001b[0m TimeoutExpired(\u001b[96mself\u001b[0m.args, timeout)      \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1952 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0mdelay = \u001b[96mmin\u001b[0m(delay * \u001b[94m2\u001b[0m, remaining, \u001b[94m.05\u001b[0m)            \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1953 \u001b[2m│   │   │   │   │   \u001b[0mtime.sleep(delay)                                 \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1954 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94melse\u001b[0m:                                                     \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1955 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[94mwhile\u001b[0m \u001b[96mself\u001b[0m.returncode \u001b[95mis\u001b[0m \u001b[94mNone\u001b[0m:                        \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1956 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0m\u001b[94mwith\u001b[0m \u001b[96mself\u001b[0m._waitpid_lock:                          \u001b[31m│\u001b[0m\n",
            "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
            "\u001b[1;91mKeyboardInterrupt\u001b[0m\n",
            "\u001b[31m╭─\u001b[0m\u001b[31m────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m─────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[2;33m/content/diffusers/examples/text_to_image/\u001b[0m\u001b[1;33mtrain_text_to_image_lora.py\u001b[0m:\u001b[94m949\u001b[0m in \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[92m<module>\u001b[0m                                                                     \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m946 \u001b[0m                                                                       \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m947 \u001b[0m                                                                       \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m948 \u001b[0m\u001b[94mif\u001b[0m \u001b[91m__name__\u001b[0m == \u001b[33m\"\u001b[0m\u001b[33m__main__\u001b[0m\u001b[33m\"\u001b[0m:                                             \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m949 \u001b[2m│   \u001b[0mmain()                                                             \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m950 \u001b[0m                                                                       \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[2;33m/content/diffusers/examples/text_to_image/\u001b[0m\u001b[1;33mtrain_text_to_image_lora.py\u001b[0m:\u001b[94m776\u001b[0m in \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[92mmain\u001b[0m                                                                         \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m773 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0m\u001b[94mraise\u001b[0m \u001b[96mValueError\u001b[0m(\u001b[33mf\u001b[0m\u001b[33m\"\u001b[0m\u001b[33mUnknown prediction type \u001b[0m\u001b[33m{\u001b[0mnoise_ \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m774 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m                                                       \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m775 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[2m# Predict the noise residual and compute loss\u001b[0m          \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m776 \u001b[2m│   │   │   │   \u001b[0mmodel_pred = unet(noisy_latents, timesteps, encoder_hi \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m777 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m                                                       \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m778 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[94mif\u001b[0m args.snr_gamma \u001b[95mis\u001b[0m \u001b[94mNone\u001b[0m:                             \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m779 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0mloss = F.mse_loss(model_pred.float(), target.float \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/\u001b[0m\u001b[1;33mmodule.py\u001b[0m:\u001b[94m1501\u001b[0m in   \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[92m_call_impl\u001b[0m                                                                   \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1498 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m (\u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._backward_pre_hooks \u001b[95mor\u001b[0m \u001b[96ms\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1499 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_backward_pre_hooks \u001b[95mor\u001b[0m _global_backward_hoo \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1500 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_forward_hooks \u001b[95mor\u001b[0m _global_forward_pre_hooks \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1501 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m forward_call(*args, **kwargs)                      \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1502 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Do not call functions when jit is used\u001b[0m                      \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1503 \u001b[0m\u001b[2m│   │   \u001b[0mfull_backward_hooks, non_full_backward_hooks = [], []         \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1504 \u001b[0m\u001b[2m│   │   \u001b[0mbackward_pre_hooks = []                                       \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/diffusers/models/\u001b[0m\u001b[1;33munet_2d_condition.p\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[1;33my\u001b[0m:\u001b[94m956\u001b[0m in \u001b[92mforward\u001b[0m                                                             \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m953 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mupsample_size = down_block_res_samples[-\u001b[94m1\u001b[0m].shape[\u001b[94m2\u001b[0m:]   \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m954 \u001b[0m\u001b[2m│   │   │   \u001b[0m                                                           \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m955 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mhasattr\u001b[0m(upsample_block, \u001b[33m\"\u001b[0m\u001b[33mhas_cross_attention\u001b[0m\u001b[33m\"\u001b[0m) \u001b[95mand\u001b[0m upsa \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m956 \u001b[2m│   │   │   │   \u001b[0msample = upsample_block(                               \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m957 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0mhidden_states=sample,                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m958 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0mtemb=emb,                                          \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m959 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0mres_hidden_states_tuple=res_samples,               \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/\u001b[0m\u001b[1;33mmodule.py\u001b[0m:\u001b[94m1501\u001b[0m in   \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[92m_call_impl\u001b[0m                                                                   \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1498 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m (\u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._backward_pre_hooks \u001b[95mor\u001b[0m \u001b[96ms\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1499 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_backward_pre_hooks \u001b[95mor\u001b[0m _global_backward_hoo \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1500 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_forward_hooks \u001b[95mor\u001b[0m _global_forward_pre_hooks \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1501 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m forward_call(*args, **kwargs)                      \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1502 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Do not call functions when jit is used\u001b[0m                      \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1503 \u001b[0m\u001b[2m│   │   \u001b[0mfull_backward_hooks, non_full_backward_hooks = [], []         \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1504 \u001b[0m\u001b[2m│   │   \u001b[0mbackward_pre_hooks = []                                       \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/diffusers/models/\u001b[0m\u001b[1;33munet_2d_blocks.py\u001b[0m:\u001b[94m2\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[94m127\u001b[0m in \u001b[92mforward\u001b[0m                                                               \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m2124 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m)[\u001b[94m0\u001b[0m]                                                  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m2125 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94melse\u001b[0m:                                                     \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m2126 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mhidden_states = resnet(hidden_states, temb)           \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m2127 \u001b[2m│   │   │   │   \u001b[0mhidden_states = attn(                                 \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m2128 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0mhidden_states,                                    \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m2129 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0mencoder_hidden_states=encoder_hidden_states,      \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m2130 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0mcross_attention_kwargs=cross_attention_kwargs,    \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/\u001b[0m\u001b[1;33mmodule.py\u001b[0m:\u001b[94m1501\u001b[0m in   \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[92m_call_impl\u001b[0m                                                                   \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1498 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m (\u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._backward_pre_hooks \u001b[95mor\u001b[0m \u001b[96ms\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1499 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_backward_pre_hooks \u001b[95mor\u001b[0m _global_backward_hoo \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1500 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_forward_hooks \u001b[95mor\u001b[0m _global_forward_pre_hooks \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1501 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m forward_call(*args, **kwargs)                      \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1502 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Do not call functions when jit is used\u001b[0m                      \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1503 \u001b[0m\u001b[2m│   │   \u001b[0mfull_backward_hooks, non_full_backward_hooks = [], []         \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1504 \u001b[0m\u001b[2m│   │   \u001b[0mbackward_pre_hooks = []                                       \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/diffusers/models/\u001b[0m\u001b[1;33mtransformer_2d.py\u001b[0m:\u001b[94m2\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[94m91\u001b[0m in \u001b[92mforward\u001b[0m                                                                \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m288 \u001b[0m\u001b[2m│   │   \u001b[0m                                                               \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m289 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# 2. Blocks\u001b[0m                                                    \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m290 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mfor\u001b[0m block \u001b[95min\u001b[0m \u001b[96mself\u001b[0m.transformer_blocks:                          \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m291 \u001b[2m│   │   │   \u001b[0mhidden_states = block(                                     \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m292 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mhidden_states,                                         \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m293 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mattention_mask=attention_mask,                         \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m294 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mencoder_hidden_states=encoder_hidden_states,           \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/\u001b[0m\u001b[1;33mmodule.py\u001b[0m:\u001b[94m1501\u001b[0m in   \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[92m_call_impl\u001b[0m                                                                   \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1498 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m (\u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._backward_pre_hooks \u001b[95mor\u001b[0m \u001b[96ms\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1499 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_backward_pre_hooks \u001b[95mor\u001b[0m _global_backward_hoo \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1500 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_forward_hooks \u001b[95mor\u001b[0m _global_forward_pre_hooks \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1501 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m forward_call(*args, **kwargs)                      \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1502 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Do not call functions when jit is used\u001b[0m                      \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1503 \u001b[0m\u001b[2m│   │   \u001b[0mfull_backward_hooks, non_full_backward_hooks = [], []         \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1504 \u001b[0m\u001b[2m│   │   \u001b[0mbackward_pre_hooks = []                                       \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/diffusers/models/\u001b[0m\u001b[1;33mattention.py\u001b[0m:\u001b[94m154\u001b[0m in \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[92mforward\u001b[0m                                                                      \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m151 \u001b[0m\u001b[2m│   │   \u001b[0m                                                               \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m152 \u001b[0m\u001b[2m│   │   \u001b[0mcross_attention_kwargs = cross_attention_kwargs \u001b[94mif\u001b[0m cross_atten \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m153 \u001b[0m\u001b[2m│   │   \u001b[0m                                                               \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m154 \u001b[2m│   │   \u001b[0mattn_output = \u001b[96mself\u001b[0m.attn1(                                      \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m155 \u001b[0m\u001b[2m│   │   │   \u001b[0mnorm_hidden_states,                                        \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m156 \u001b[0m\u001b[2m│   │   │   \u001b[0mencoder_hidden_states=encoder_hidden_states \u001b[94mif\u001b[0m \u001b[96mself\u001b[0m.only_c \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m157 \u001b[0m\u001b[2m│   │   │   \u001b[0mattention_mask=attention_mask,                             \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/\u001b[0m\u001b[1;33mmodule.py\u001b[0m:\u001b[94m1501\u001b[0m in   \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[92m_call_impl\u001b[0m                                                                   \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1498 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m (\u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._backward_pre_hooks \u001b[95mor\u001b[0m \u001b[96ms\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1499 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_backward_pre_hooks \u001b[95mor\u001b[0m _global_backward_hoo \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1500 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_forward_hooks \u001b[95mor\u001b[0m _global_forward_pre_hooks \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1501 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m forward_call(*args, **kwargs)                      \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1502 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Do not call functions when jit is used\u001b[0m                      \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1503 \u001b[0m\u001b[2m│   │   \u001b[0mfull_backward_hooks, non_full_backward_hooks = [], []         \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1504 \u001b[0m\u001b[2m│   │   \u001b[0mbackward_pre_hooks = []                                       \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/diffusers/models/\u001b[0m\u001b[1;33mattention_processor\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[1;33m.py\u001b[0m:\u001b[94m321\u001b[0m in \u001b[92mforward\u001b[0m                                                           \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m 318 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# The `Attention` class can call different attention processo\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m 319 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# here we simply pass along all tensors to the selected proce\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m 320 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# For standard processors that are defined here, `**cross_att\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 321 \u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96mself\u001b[0m.processor(                                        \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m 322 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[96mself\u001b[0m,                                                     \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m 323 \u001b[0m\u001b[2m│   │   │   \u001b[0mhidden_states,                                            \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m 324 \u001b[0m\u001b[2m│   │   │   \u001b[0mencoder_hidden_states=encoder_hidden_states,              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/diffusers/models/\u001b[0m\u001b[1;33mattention_processor\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[1;33m.py\u001b[0m:\u001b[94m603\u001b[0m in \u001b[92m__call__\u001b[0m                                                          \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m 600 \u001b[0m\u001b[2m│   │   \u001b[0m                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m 601 \u001b[0m\u001b[2m│   │   \u001b[0mattention_probs = attn.get_attention_scores(query, key, atten \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m 602 \u001b[0m\u001b[2m│   │   \u001b[0mhidden_states = torch.bmm(attention_probs, value)             \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 603 \u001b[2m│   │   \u001b[0mhidden_states = attn.batch_to_head_dim(hidden_states)         \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m 604 \u001b[0m\u001b[2m│   │   \u001b[0m                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m 605 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# linear proj\u001b[0m                                                 \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m 606 \u001b[0m\u001b[2m│   │   \u001b[0mhidden_states = attn.to_out[\u001b[94m0\u001b[0m](hidden_states) + scale * \u001b[96mself\u001b[0m. \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/diffusers/models/\u001b[0m\u001b[1;33mattention_processor\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[1;33m.py\u001b[0m:\u001b[94m333\u001b[0m in \u001b[92mbatch_to_head_dim\u001b[0m                                                 \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m 330 \u001b[0m\u001b[2m│   │   \u001b[0mhead_size = \u001b[96mself\u001b[0m.heads                                        \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m 331 \u001b[0m\u001b[2m│   │   \u001b[0mbatch_size, seq_len, dim = tensor.shape                       \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m 332 \u001b[0m\u001b[2m│   │   \u001b[0mtensor = tensor.reshape(batch_size // head_size, head_size, s \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 333 \u001b[2m│   │   \u001b[0mtensor = tensor.permute(\u001b[94m0\u001b[0m, \u001b[94m2\u001b[0m, \u001b[94m1\u001b[0m, \u001b[94m3\u001b[0m).reshape(batch_size // hea \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m 334 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m tensor                                                 \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m 335 \u001b[0m\u001b[2m│   \u001b[0m                                                                  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m 336 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mhead_to_batch_dim\u001b[0m(\u001b[96mself\u001b[0m, tensor, out_dim=\u001b[94m3\u001b[0m):                   \u001b[31m│\u001b[0m\n",
            "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
            "\u001b[1;91mKeyboardInterrupt\u001b[0m\n",
            "Steps:   9% 7370/83300 [27:25<4:42:35,  4.48it/s, lr=0.0001, step_loss=0.0427]\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- GPU 런타임을 돌리지 않으면 fp16으로 mixed precision하는 게 불가능\n",
        "- 모델하고 데이터셋 주소를 변수로 넣지 않고 직접 넣음(변수 앞에 쓰는$가 문제가 된다는 것 같았음)"
      ],
      "metadata": {
        "id": "iGxJTjQSbeaU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from diffusers import StableDiffusionPipeline\n",
        "import torch\n",
        "\n",
        "model_path = \"sayakpaul/sd-model-finetuned-lora-t4\"\n",
        "pipe = StableDiffusionPipeline.from_pretrained(\"CompVis/stable-diffusion-v1-4\", torch_dtype=torch.float16)\n",
        "pipe.unet.load_attn_procs(model_path)\n",
        "pipe.to(\"cuda\")\n",
        "\n",
        "prompt = \"A pokemon with yellow skin, cute eyes, black edged tail.\"\n",
        "image = pipe(prompt, num_inference_steps=30, guidance_scale=7.5).images[0]\n",
        "image.save(\"pokemon2.png\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87,
          "referenced_widgets": [
            "c98786c34d004028a13c8c06c4c0efee",
            "7aea453302324ae68697f636a48b1b33",
            "e173ab8c0d5c43f0bc545677b0e7faee",
            "758201684fd4430796d63033103ee71b",
            "81de710ebd56477ca93f0ad3cd0102f2",
            "f418e99a5aa7459bac282aae8e1cfd28",
            "5bb4a1e686794f40931244e8c67b7c54",
            "d3511d890d7146598bc4592e6ad36f78",
            "cee54dac7f4e4a2b8953ea19ed9f585f",
            "074b64f21bdf4169aa47ca2b75c4ae19",
            "067f3019a47248d38e55616b8d9e3f45"
          ]
        },
        "id": "F-N6tZhLR6KZ",
        "outputId": "38d0fdc9-6bc8-415d-b946-ed08eb8e21be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/30 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c98786c34d004028a13c8c06c4c0efee"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EtqECgmYT9kR",
        "outputId": "63c759e6-2182-47c8-895e-d411397ef1fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/diffusers/examples/text_to_image\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "여기로 가서 pokemon.png를 찾아보니 이미지가 생성되었다. 파인튜닝을 직접 해서 나온 결과인지는 모르겠지만.."
      ],
      "metadata": {
        "id": "8kYP6u7qdBA8"
      }
    }
  ]
}